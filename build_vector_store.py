# build_vector_store.py


import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.docstore.document import Document
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")


# ğŸ”¹ CSV ë¡œë”©
import chardet

with open("/Users/anhyemin/Desktop/á„ƒá…¢á„’á…¡á†¨á„‹á…¯á†«/*2025_á„‡á…©á†·/á„‘á…³á„…á…¦á†¨á„á…µá„á…¥á†·/Todak_talk/pythonProject/chatbot/data/QAá„á…¡á„á…¦á„€á…©á„…á…µ2.csv", "rb") as f:
    result = chardet.detect(f.read())
    encoding = result['encoding']

df = pd.read_csv("/Users/anhyemin/Desktop/á„ƒá…¢á„’á…¡á†¨á„‹á…¯á†«/*2025_á„‡á…©á†·/á„‘á…³á„…á…¦á†¨á„á…µá„á…¥á†·/Todak_talk/pythonProject/chatbot/data/QAá„á…¡á„á…¦á„€á…©á„…á…µ2.csv", encoding=encoding)
df.dropna(subset=["Q", "A"], inplace=True)

# ğŸ”¹ Q + A ë¬¶ì–´ì„œ context êµ¬ì„±
docs = [
    Document(page_content=f"ì§ˆë¬¸: {row['Q']}\në‹µë³€: {row['A']}")
    for _, row in df.iterrows()
]

# âœ… Embedding ìƒì„±
embedding = OpenAIEmbeddings(openai_api_key=api_key)

# âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
vectorstore = FAISS.from_documents(docs, embedding)
vectorstore.save_local("rag_faiss")

print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ")

def load_vector_store():
    return FAISS.load_local("rag_faiss", embedding, allow_dangerous_deserialization=True)
